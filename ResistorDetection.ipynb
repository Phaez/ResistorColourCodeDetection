{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #Select first GPU detected\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization, MaxPool2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import cv2\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import random\n",
    "import colorsys\n",
    "import imutils\n",
    "\n",
    "DATA_DIR = \"./dataset2/resistors/\"\n",
    "DATASET_TRAIN_PATH = \"./dataset2/resistors_train.txt\"\n",
    "DATASET_TEST_PATH = \"./dataset2/resistors_test.txt\"\n",
    "LABEL_PATH = \"./dataset2/resistors_labels.txt\"\n",
    "YOLO_LABELS = \"./dataset2/coco/coco.names\"\n",
    "YOLO_WEIGHTS = \"./dataset2/yolov3.weights\"\n",
    "\n",
    "TRAIN_SAVE_BEST_ONLY        = True # saves only best model according validation loss (True recommended)\n",
    "TRAIN_SAVE_CHECKPOINT       = False \n",
    "\n",
    "TRAIN_MODEL_NAME = \"yolov3_resistors\"\n",
    "TRAIN_CHECKPOINTS_FOLDER = \"checkpoints2\"\n",
    "TRAIN_LOGDIR = \"log\"\n",
    "\n",
    "INPUT_SIZE_TRAIN = 416\n",
    "INPUT_SIZE_TEST = 416\n",
    "YOLO_INPUT_SIZE = 416\n",
    "BATCH_SIZE_TRAIN = 8\n",
    "BATCH_SIZE_TEST = 4\n",
    "\n",
    "TEST_SCORE_THRESHOLD = 0.4\n",
    "TEST_IOU_THRESHOLD = 0.45\n",
    "TRAIN_LR_INIT = 1e-4\n",
    "TRAIN_LR_END = 1e-6\n",
    "\n",
    "AUG_TRAIN = True\n",
    "AUG_TEST = False\n",
    "\n",
    "WARMUP_EPOCHS = 5\n",
    "TRAIN_EPOCHS = 300\n",
    "\n",
    "YOLO_IOU_LOSS_THRESH = 0.5\n",
    "YOLO_STRIDES = [8, 16, 32]\n",
    "YOLO_ANCHORS = [[[10,  13], [16,   30], [33,   23]],\n",
    "               [[30,  61], [62,   45], [59,  119]],\n",
    "               [[116, 90], [156, 198], [373, 326]]]\n",
    "STRIDES = np.array(YOLO_STRIDES)\n",
    "ANCHORS = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
    "\n",
    "YOLO_ANCHOR_PER_SCALE = 3\n",
    "YOLO_MAX_BBOX_PER_SCALE = 100\n",
    "\n",
    "LOAD_IMAGES_INTO_RAM = False\n",
    "\n",
    "COLOUR_BOUNDS = [\n",
    "                [(0, 0, 0)      , (179, 255, 93)  , \"BLACK\"  , 0 , (0,0,0)       ],    \n",
    "                [(0, 90, 10)    , (15, 250, 100)  , \"BROWN\"  , 1 , (0,51,102)    ],    \n",
    "                [(0, 30, 80)    , (10, 255, 200)  , \"RED\"    , 2 , (0,0,255)     ],\n",
    "                [(10, 70, 70)   , (25, 255, 200)  , \"ORANGE\" , 3 , (0,128,255)   ], \n",
    "                [(30, 170, 100) , (40, 250, 255)  , \"YELLOW\" , 4 , (0,255,255)   ],\n",
    "                [(35, 20, 110)  , (60, 45, 120)   , \"GREEN\"  , 5 , (0,255,0)     ],  \n",
    "                [(65, 0, 85)    , (115, 30, 147)  , \"BLUE\"   , 6 , (255,0,0)     ],  \n",
    "                [(120, 40, 100) , (140, 250, 220) , \"PURPLE\" , 7 , (255,0,127)   ], \n",
    "                [(0, 0, 50)     , (179, 50, 80)   , \"GRAY\"   , 8 , (128,128,128) ],      \n",
    "                [(0, 0, 90)     , (179, 15, 250)  , \"WHITE\"  , 9 , (255,255,255) ],\n",
    "                ];\n",
    "\n",
    "RED_TOP_LOWER = (160, 30, 80)\n",
    "RED_TOP_UPPER = (179, 255, 200)\n",
    "MIN_AREA = 700\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "CLASSES = [\"resistor\", \"bands\"]\n",
    "\n",
    "def ParseXML(image, file):\n",
    "    for xml_file in glob.glob(image + \"/*.xml\"):\n",
    "        tree = ET.parse(open(xml_file))\n",
    "        root = tree.getroot()\n",
    "        image_name = root.find(\"filename\").text\n",
    "        image_path = image + \"/\" + image_name\n",
    "        for i, obj in enumerate(root.iter(\"object\")):\n",
    "            difficult = obj.find(\"difficult\").text\n",
    "            cls = obj.find(\"name\").text\n",
    "            if cls not in CLASSES:\n",
    "                CLASSES.append(cls)\n",
    "            cls_id = CLASSES.index(cls)\n",
    "            xmlbox = obj.find(\"bndbox\")\n",
    "            OBJECT = (str(int(float(xmlbox.find('xmin').text))) + ','\n",
    "                      +str(int(float(xmlbox.find('ymin').text))) + ','\n",
    "                      +str(int(float(xmlbox.find('xmax').text))) + ','\n",
    "                      +str(int(float(xmlbox.find('ymax').text))) + ','\n",
    "                      +str(cls_id))\n",
    "            image_path += \" \" + OBJECT\n",
    "        file.write(image_path + '\\n')\n",
    "\t\t\n",
    "def XMLtoYOLO():\n",
    "    for i, folder in enumerate([\"train\", \"test\"]):\n",
    "        with open([DATASET_TRAIN_PATH, DATASET_TEST_PATH][i], 'w') as file:\n",
    "            image_path = os.path.join(os.getcwd() + DATA_DIR[1:] + folder)\n",
    "            ParseXML(image_path, file)\n",
    "    print(\"Dataset converted\")\n",
    "    with open(LABEL_PATH, 'w') as file:\n",
    "        for name in CLASSES:\n",
    "            file.write(str(name) + '\\n')\t\t\n",
    "\t\t\t\n",
    "class Dataset(object):\n",
    "    def __init__(self, dataset_type, input_size):\n",
    "        self.label_path = DATASET_TRAIN_PATH if dataset_type == \"train\" else DATASET_TEST_PATH\n",
    "        self.input_size = INPUT_SIZE_TRAIN if dataset_type == \"train\" else INPUT_SIZE_TRAIN\n",
    "        self.batch_size = BATCH_SIZE_TRAIN if dataset_type == \"train\" else BATCH_SIZE_TEST\n",
    "        self.data_aug = AUG_TRAIN if dataset_type == \"train\" else AUG_TEST\n",
    "        \n",
    "        self.train_input_sizes = INPUT_SIZE_TRAIN\n",
    "        self.strides = np.array(YOLO_STRIDES)\n",
    "        self.classes = read_class_names(LABEL_PATH)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.anchors = (np.array(YOLO_ANCHORS).T/self.strides).T\n",
    "        self.anchor_per_scale = YOLO_ANCHOR_PER_SCALE\n",
    "        self.max_bbox_per_scale = YOLO_MAX_BBOX_PER_SCALE\n",
    "        \n",
    "        self.annotations = self.load_annotations(dataset_type)\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batches = int(np.ceil(self.num_samples / self.batch_size))\n",
    "        self.batch_count = 0\n",
    "        \n",
    "    def load_annotations(self, dataset_type):\n",
    "        final_annotations = []\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            txt = f.readlines()\n",
    "            annotations = [line.strip() for line in txt if len(line.strip().split()[1:]) != 0]\n",
    "        np.random.shuffle(annotations)\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            # fully parse annotations\n",
    "            line = annotation.split()\n",
    "            image_path, index = \"\", 1\n",
    "            for i, one_line in enumerate(line):\n",
    "                if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                    if image_path != \"\": image_path += \" \"\n",
    "                    image_path += one_line\n",
    "                else:\n",
    "                    index = i\n",
    "                    break\n",
    "            if not os.path.exists(image_path):\n",
    "                raise KeyError(\"%s does not exist ... \" %image_path)\n",
    "            if LOAD_IMAGES_INTO_RAM:\n",
    "                image = cv2.imread(image_path)\n",
    "            else:\n",
    "                image = ''\n",
    "            final_annotations.append([image_path, line[index:], image])\n",
    "        return final_annotations\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def Delete_bad_annotation(self, bad_annotation):\n",
    "        print(f'Deleting {bad_annotation} annotation line')\n",
    "        bad_image_path = bad_annotation[0]\n",
    "        bad_image_name = bad_annotation[0].split('/')[-1] # can be used to delete bad image\n",
    "        bad_xml_path = bad_annotation[0][:-3]+'xml' # can be used to delete bad xml file\n",
    "\n",
    "        # remove bad annotation line from annotation file\n",
    "        with open(self.label_path, \"r+\") as f:\n",
    "            d = f.readlines()\n",
    "            f.seek(0)\n",
    "            for i in d:\n",
    "                if bad_image_name not in i:\n",
    "                    f.write(i)\n",
    "            f.truncate()\n",
    "    \n",
    "    def __next__(self):\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.train_input_size = random.choice([self.train_input_sizes])\n",
    "            self.train_output_sizes = self.train_input_size // self.strides\n",
    "\n",
    "            batch_image = np.zeros((self.batch_size, self.train_input_size, self.train_input_size, 3), dtype=np.float32)\n",
    "\n",
    "            batch_label_sbbox = np.zeros((self.batch_size, self.train_output_sizes[0], self.train_output_sizes[0],\n",
    "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_mbbox = np.zeros((self.batch_size, self.train_output_sizes[1], self.train_output_sizes[1],\n",
    "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_lbbox = np.zeros((self.batch_size, self.train_output_sizes[2], self.train_output_sizes[2],\n",
    "                                          self.anchor_per_scale, 5 + self.num_classes), dtype=np.float32)\n",
    "\n",
    "            batch_sbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
    "            batch_mbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
    "            batch_lbboxes = np.zeros((self.batch_size, self.max_bbox_per_scale, 4), dtype=np.float32)\n",
    "\n",
    "            exceptions = False\n",
    "            num = 0\n",
    "            if self.batch_count < self.num_batches:\n",
    "                while num < self.batch_size:\n",
    "                    index = self.batch_count * self.batch_size + num\n",
    "                    if index >= self.num_samples: index -= self.num_samples\n",
    "                    annotation = self.annotations[index]\n",
    "                    image, bboxes = self.parse_annotation(annotation)\n",
    "                    try:\n",
    "                        label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes)\n",
    "                    except IndexError:\n",
    "                        exceptions = True\n",
    "                        self.Delete_bad_annotation(annotation)\n",
    "                        print(\"IndexError, something wrong with\", annotation[0], \"removed this line from annotation file\")\n",
    "\n",
    "                    batch_image[num, :, :, :] = image\n",
    "                    batch_label_sbbox[num, :, :, :, :] = label_sbbox\n",
    "                    batch_label_mbbox[num, :, :, :, :] = label_mbbox\n",
    "                    batch_label_lbbox[num, :, :, :, :] = label_lbbox\n",
    "                    batch_sbboxes[num, :, :] = sbboxes\n",
    "                    batch_mbboxes[num, :, :] = mbboxes\n",
    "                    batch_lbboxes[num, :, :] = lbboxes\n",
    "                    num += 1\n",
    "\n",
    "                if exceptions: \n",
    "                    print('\\n')\n",
    "                    raise Exception(\"There were problems with dataset, I fixed them, now restart the training process.\")\n",
    "                self.batch_count += 1\n",
    "                batch_smaller_target = batch_label_sbbox, batch_sbboxes\n",
    "                batch_medium_target  = batch_label_mbbox, batch_mbboxes\n",
    "                batch_larger_target  = batch_label_lbbox, batch_lbboxes\n",
    "\n",
    "                return batch_image, (batch_smaller_target, batch_medium_target, batch_larger_target)\n",
    "            else:\n",
    "                self.batch_count = 0\n",
    "                np.random.shuffle(self.annotations)\n",
    "                raise StopIteration\n",
    "\n",
    "    def random_horizontal_flip(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            _, w, _ = image.shape\n",
    "            image = image[:, ::-1, :]\n",
    "            bboxes[:, [0,2]] = w - bboxes[:, [2,0]]\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def random_crop(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            h, w, _ = image.shape\n",
    "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "            max_l_trans = max_bbox[0]\n",
    "            max_u_trans = max_bbox[1]\n",
    "            max_r_trans = w - max_bbox[2]\n",
    "            max_d_trans = h - max_bbox[3]\n",
    "\n",
    "            crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "            crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "            crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "            crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "            image = image[crop_ymin : crop_ymax, crop_xmin : crop_xmax]\n",
    "\n",
    "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def random_translate(self, image, bboxes):\n",
    "        if random.random() < 0.5:\n",
    "            h, w, _ = image.shape\n",
    "            max_bbox = np.concatenate([np.min(bboxes[:, 0:2], axis=0), np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "            max_l_trans = max_bbox[0]\n",
    "            max_u_trans = max_bbox[1]\n",
    "            max_r_trans = w - max_bbox[2]\n",
    "            max_d_trans = h - max_bbox[3]\n",
    "\n",
    "            tx = random.uniform(-(max_l_trans - 1), (max_r_trans - 1))\n",
    "            ty = random.uniform(-(max_u_trans - 1), (max_d_trans - 1))\n",
    "\n",
    "            M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "            image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "            bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "            bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "    def parse_annotation(self, annotation, mAP = 'False'):\n",
    "        if LOAD_IMAGES_INTO_RAM:\n",
    "            image_path = annotation[0]\n",
    "            image = annotation[2]\n",
    "        else:\n",
    "            image_path = annotation[0]\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
    "\n",
    "        if self.data_aug:\n",
    "            image, bboxes = self.random_horizontal_flip(np.copy(image), np.copy(bboxes))\n",
    "            image, bboxes = self.random_crop(np.copy(image), np.copy(bboxes))\n",
    "            image, bboxes = self.random_translate(np.copy(image), np.copy(bboxes))\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if mAP == True: \n",
    "            return image, bboxes\n",
    "        \n",
    "        image, bboxes = image_preprocess(np.copy(image), [self.input_size, self.input_size], np.copy(bboxes))\n",
    "        return image, bboxes\n",
    "\n",
    "    def preprocess_true_boxes(self, bboxes):\n",
    "        label = [np.zeros((self.train_output_sizes[i], self.train_output_sizes[i], self.anchor_per_scale,\n",
    "                           5 + self.num_classes)) for i in range(3)]\n",
    "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4)) for _ in range(3)]\n",
    "        bbox_count = np.zeros((3,))\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            bbox_coor = bbox[:4]\n",
    "            bbox_class_ind = bbox[4]\n",
    "\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float)\n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "            uniform_distribution = np.full(self.num_classes, 1.0 / self.num_classes)\n",
    "            deta = 0.01\n",
    "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
    "\n",
    "            bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis]\n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False\n",
    "            for i in range(3):\n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "\n",
    "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "                iou_mask = iou_scale > 0.3\n",
    "\n",
    "                if np.any(iou_mask):\n",
    "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
    "\n",
    "                    label[i][yind, xind, iou_mask, :] = 0\n",
    "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
    "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    bbox_ind = int(bbox_count[i] % self.max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1\n",
    "\n",
    "                    exist_positive = True\n",
    "\n",
    "            if not exist_positive:\n",
    "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "                best_detect = int(best_anchor_ind / self.anchor_per_scale)\n",
    "                best_anchor = int(best_anchor_ind % self.anchor_per_scale)\n",
    "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
    "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
    "                bbox_count[best_detect] += 1\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "        return label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_batches\t\t\t\n",
    "\t\t\t\n",
    "class BatchNormalization(BatchNormalization):\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n",
    "    \n",
    "def residual_block(input_layer, input_channel, filter_num1, filter_num2):\n",
    "    short_cut = input_layer\n",
    "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1))\n",
    "    conv = convolutional(conv, filters_shape=(3, 3, filter_num1, filter_num2))\n",
    "\n",
    "    residual_output = short_cut + conv\n",
    "    return residual_output\n",
    "\n",
    "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True):\n",
    "    if downsample:\n",
    "        input_layer = ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
    "        padding = 'valid'\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "        padding = 'same'\n",
    "\n",
    "    conv = Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides,\n",
    "                  padding=padding, use_bias=not bn, kernel_regularizer=l2(0.0005),\n",
    "                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    if activate == True:\n",
    "        conv = LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "def upsample(input_layer):\n",
    "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')\n",
    "\n",
    "def darknet53(input_data):\n",
    "    input_data = convolutional(input_data, (3, 3, 3, 32))\n",
    "    input_data = convolutional(input_data, (3, 3, 32, 64), downsample=True)\n",
    "    \n",
    "    for i in range(1):\n",
    "        input_data = residual_block(input_data, 64, 32, 64)\n",
    "    input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True)\n",
    "    \n",
    "    for i in range(2):\n",
    "        input_data = residual_block(input_data, 128, 64, 128)\n",
    "    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True)\n",
    "    \n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 256, 128, 256)\n",
    "        \n",
    "    route_1 = input_data\n",
    "    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True)\n",
    "    \n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 512, 256, 512)\n",
    "        \n",
    "    route_2 = input_data\n",
    "    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True)\n",
    "    \n",
    "    for i in range(4):\n",
    "        input_data = residual_block(input_data, 1024, 512, 1024)\n",
    "        \n",
    "    return route_1, route_2, input_data\n",
    "        \n",
    "def YOLOv3(input_layer, NUM_CLASS):\n",
    "    # After the input layer enters the Darknet-53 network, we get three branches\n",
    "    route_1, route_2, conv = darknet53(input_layer)\n",
    "    # See the orange module (DBL) in the figure above, a total of 5 Subconvolution operation\n",
    "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
    "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
    "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
    "    conv = convolutional(conv, (3, 3,  512, 1024))\n",
    "    conv = convolutional(conv, (1, 1, 1024,  512))\n",
    "    conv_lobj_branch = convolutional(conv, (3, 3, 512, 1024))\n",
    "    \n",
    "    # conv_lbbox is used to predict large-sized objects , Shape = [None, 13, 13, 255] \n",
    "    conv_lbbox = convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, (1, 1,  512,  256))\n",
    "    # upsample here uses the nearest neighbor interpolation method, which has the advantage that the\n",
    "    # upsampling process does not need to learn, thereby reducing the network parameter  \n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_2], axis=-1)\n",
    "    conv = convolutional(conv, (1, 1, 768, 256))\n",
    "    conv = convolutional(conv, (3, 3, 256, 512))\n",
    "    conv = convolutional(conv, (1, 1, 512, 256))\n",
    "    conv = convolutional(conv, (3, 3, 256, 512))\n",
    "    conv = convolutional(conv, (1, 1, 512, 256))\n",
    "    conv_mobj_branch = convolutional(conv, (3, 3, 256, 512))\n",
    "\n",
    "    # conv_mbbox is used to predict medium-sized objects, shape = [None, 26, 26, 255]\n",
    "    conv_mbbox = convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, (1, 1, 256, 128))\n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_1], axis=-1)\n",
    "    conv = convolutional(conv, (1, 1, 384, 128))\n",
    "    conv = convolutional(conv, (3, 3, 128, 256))\n",
    "    conv = convolutional(conv, (1, 1, 256, 128))\n",
    "    conv = convolutional(conv, (3, 3, 128, 256))\n",
    "    conv = convolutional(conv, (1, 1, 256, 128))\n",
    "    conv_sobj_branch = convolutional(conv, (3, 3, 128, 256))\n",
    "    \n",
    "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
    "    conv_sbbox = convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
    "        \n",
    "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
    "\n",
    "def decode(conv_output, NUM_CLASS, i=0):\n",
    "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "\n",
    "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
    "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
    "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
    "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box \n",
    "\n",
    "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
    "    y = tf.range(output_size, dtype=tf.int32)\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y = tf.tile(y, [1, output_size])\n",
    "    x = tf.range(output_size,dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.tile(x, [output_size, 1])\n",
    "\n",
    "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    # Calculate the center position of the prediction box:\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
    "    # Calculate the length and width of the prediction box:\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
    "\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
    "\n",
    "    # calculating the predicted probability category box object\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "\n",
    "def load_yolo_weights(model, weights_file):\n",
    "    tf.keras.backend.clear_session() # used to reset layer names\n",
    "    # load Darknet original weights to TensorFlow model\n",
    "    range1 = 75\n",
    "    range2 = [58, 66, 74]\n",
    "    \n",
    "    with open(weights_file, 'rb') as wf:\n",
    "        major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "        j = 0\n",
    "        for i in range(range1):\n",
    "            if i > 0:\n",
    "                conv_layer_name = 'conv2d_%d' %i\n",
    "            else:\n",
    "                conv_layer_name = 'conv2d'\n",
    "                \n",
    "            if j > 0:\n",
    "                bn_layer_name = 'batch_normalization_%d' %j\n",
    "            else:\n",
    "                bn_layer_name = 'batch_normalization'\n",
    "            \n",
    "            conv_layer = model.get_layer(conv_layer_name)\n",
    "            filters = conv_layer.filters\n",
    "            k_size = conv_layer.kernel_size[0]\n",
    "            in_dim = conv_layer.input_shape[-1]\n",
    "\n",
    "            if i not in range2:\n",
    "                # darknet weights: [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf weights: [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "                bn_layer = model.get_layer(bn_layer_name)\n",
    "                j += 1\n",
    "            else:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, in_dim, k_size, k_size)\n",
    "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if i not in range2:\n",
    "                conv_layer.set_weights([conv_weights])\n",
    "                bn_layer.set_weights(bn_weights)\n",
    "            else:\n",
    "                conv_layer.set_weights([conv_weights, conv_bias])\n",
    "\n",
    "        assert len(wf.read()) == 0, 'failed to read all data'\n",
    "        \n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area\n",
    "\n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
    "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
    "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    # Calculate the iou value between the two bounding boxes\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    # Calculate the coordinates of the upper left corner and the lower right corner of the smallest closed convex surface\n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "\n",
    "    # Calculate the area of the smallest closed convex surface C\n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "\n",
    "    # Calculate the GIoU value according to the GioU formula  \n",
    "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
    "\n",
    "    return giou\n",
    "\n",
    "# testing (should be better than giou)\n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    "\n",
    "    return iou - ciou_term\n",
    "\n",
    "def compute_loss(pred, conv, label, bboxes, i=0, classes=YOLO_LABELS):\n",
    "    NUM_CLASS = len(read_class_names(classes))\n",
    "    conv_shape  = tf.shape(conv)\n",
    "    batch_size  = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size  = STRIDES[i] * output_size\n",
    "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "\n",
    "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
    "    pred_conf     = pred[:, :, :, :, 4:5]\n",
    "\n",
    "    label_xywh    = label[:, :, :, :, 0:4]\n",
    "    respond_bbox  = label[:, :, :, :, 4:5]\n",
    "    label_prob    = label[:, :, :, :, 5:]\n",
    "\n",
    "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
    "    input_size = tf.cast(input_size, tf.float32)\n",
    "\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
    "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
    "\n",
    "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
    "    # Find the value of IoU with the real box The largest prediction box\n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
    "\n",
    "    # If the largest iou is less than the threshold, it is considered that the prediction box contains no objects, then the background box\n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < YOLO_IOU_LOSS_THRESH, tf.float32 )\n",
    "\n",
    "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
    "\n",
    "    # Calculate the loss of confidence\n",
    "    # we hope that if the grid contains objects, then the network output prediction box has a confidence of 1 and 0 when there is no object.\n",
    "    conf_loss = conf_focal * (\n",
    "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
    "            +\n",
    "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
    "    )\n",
    "\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
    "\n",
    "    return giou_loss, conf_loss, prob_loss\t\t\t\n",
    "\t\t\n",
    "def CreateYolo(input_size=416, channels=3, training=False, classes=YOLO_LABELS):\n",
    "    NUM_CLASS = len(read_class_names(classes))\n",
    "    input_layer = Input([input_size, input_size, channels])\n",
    "    \n",
    "    conv_tensors = YOLOv3(input_layer, NUM_CLASS)\n",
    "    output_tensors = []\n",
    "    for i, conv_tensor in enumerate(conv_tensors):\n",
    "        pred_tensor = decode(conv_tensor, NUM_CLASS, i)\n",
    "        if training:\n",
    "            output_tensors.append(conv_tensor)\n",
    "        output_tensors.append(pred_tensor)\n",
    "        \n",
    "    YoloV3 = tf.keras.Model(input_layer, output_tensors)\n",
    "    return YoloV3\n",
    "    \n",
    "def read_class_names(path):\n",
    "        names = {}\n",
    "        with open(path, 'r') as data:\n",
    "            for ID, name in enumerate(data):\n",
    "                names[ID] = name.strip('\\n')\n",
    "        return names\t\t\t\n",
    "\n",
    "def image_preprocess(image, target_size, gt_boxes=None):\n",
    "    ih, iw    = target_size\n",
    "    h,  w, _  = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_paded\n",
    "\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_paded, gt_boxes\n",
    "\n",
    "\n",
    "def draw_bbox(image, bboxes, CLASSES=YOLO_LABELS, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
    "    NUM_CLASS = read_class_names(CLASSES)\n",
    "    num_classes = len(NUM_CLASS)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    #print(\"hsv_tuples\", hsv_tuples)\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        if class_ind == 1:\n",
    "            bbox_color = (0,0,255)\n",
    "        bbox_thick = int(0.3 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1\n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "\n",
    "        # put object rectangle\n",
    "        if class_ind == 0:\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
    "        else:\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick)\n",
    "\n",
    "        if class_ind == 0:\n",
    "            if show_label:\n",
    "                # get text label\n",
    "                score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
    "\n",
    "                if tracking: score_str = \" \"+str(score)\n",
    "\n",
    "                label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
    "\n",
    "                # get text size\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                                                                      fontScale, thickness=bbox_thick)\n",
    "                # put filled text rectangle\n",
    "                cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
    "\n",
    "                # put text above rectangle\n",
    "                cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                            fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area    = boxes1_area + boxes2_area - inter_area\n",
    "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious\n",
    "\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    \"\"\"\n",
    "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
    "\n",
    "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
    "          https://github.com/bharatsingh430/soft-nms\n",
    "    \"\"\"\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            # Process 3: Calculate this bounding box A and\n",
    "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0\n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0.\n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes\n",
    "\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
    "    valid_scale=[0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
    "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2\n",
    "    dh = (input_size - resize_ratio * org_h) / 2\n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. clip some boxes those are out of range\n",
    "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
    "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0\n",
    "\n",
    "    # 4. discard some invalid boxes\n",
    "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. discard boxes with low scores\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores >= score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
    "\n",
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)\n",
    "    \n",
    "def detect_shape(c):\n",
    "    shape = \"unidentified\"\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "    if len(approx) == 3:\n",
    "        shape = \"triangle\"\n",
    "    elif len(approx) == 4:\n",
    "        shape = \"rectangle\"\n",
    "    elif len(approx) == 5:\n",
    "        shape = \"pentagon\"\n",
    "    else:\n",
    "        shape = \"circle\"\n",
    "        \n",
    "    return shape\n",
    "\n",
    "def detect_image(YoloV3, image_path, output_path, input_size=416, show=False, CLASSES=YOLO_LABELS, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
    "    original_image      = cv2.imread(image_path)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = tf.expand_dims(image_data, 0)\n",
    "\n",
    "    pred_bbox = YoloV3.predict(image_data)\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    rectCascade = cv2.CascadeClassifier(\"./dataset2/cascade/haarcascade_resistors_0.xml\")\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "        test = original_image[y1:y2, x1:x2]\n",
    "        height, width, channels = test.shape\n",
    "        resize = 0\n",
    "        if height > width:\n",
    "            resize = ResizeWithAspectRatio(test, height=900)\n",
    "        else:\n",
    "            resize = ResizeWithAspectRatio(test, width=900)\n",
    "        cv2.imshow(\"crop \" + str(i), resize)\n",
    "        height, width, channels = resize.shape\n",
    "        cv2.moveWindow(\"crop \" + str(i), int(2560/2) - int(width/2), int(1080/2) - int(height/2))\n",
    "        cv2.imwrite(output_path[:-4] + \"-crop-\" + str(i) + \".jpg\", test)\n",
    "        \n",
    "        test2 = test.copy()\n",
    "        if(bbox[5] == 1):\n",
    "            gray = cv2.cvtColor(test2, cv2.COLOR_BGR2GRAY)\n",
    "            invr = cv2.bitwise_not(gray)\n",
    "            thresh = cv2.threshold(invr, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "            hsv = cv2.cvtColor(test2, cv2.COLOR_BGR2HSV)\n",
    "            lower = np.array([105, 90, 40])\n",
    "            upper = np.array([130, 255, 255]) #blue\n",
    "            mask = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([0, 125, 90])\n",
    "            upper = np.array([4, 255, 255]) #red lower\n",
    "            mask2 = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([165, 125, 90]) #red upper\n",
    "            upper = np.array([180, 255, 255])\n",
    "            mask2_1 = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([42, 100, 100]) #green\n",
    "            upper = np.array([75, 255, 255])\n",
    "            mask3 = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([18, 95, 95])\n",
    "            upper = np.array([40, 255, 255]) #yellow/gold\n",
    "            mask4 = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([131, 100, 75])\n",
    "            upper = np.array([164, 255, 255]) #purple\n",
    "            mask5 = cv2.inRange(hsv, lower, upper)\n",
    "            lower = np.array([0, 15, 15])\n",
    "            upper = np.array([10, 175, 145]) #brown\n",
    "            mask6 = cv2.inRange(hsv, lower, upper)\n",
    "            maskf = 255*(mask + mask2 + mask2_1 + mask3 + mask4 + mask5 + mask6)\n",
    "            maskf = maskf.clip(0, 255)\n",
    "            res = cv2.bitwise_and(test2, test2, mask = maskf)\n",
    "            cv2.imshow(\"DEBUG1\", gray)\n",
    "            cv2.imshow(\"DEBUG2\", invr)\n",
    "            cv2.imshow(\"DEBUG3\", thresh)\n",
    "            cv2.imshow(\"DEBUG5\", maskf)\n",
    "            cv2.imshow(\"DEBUG6\", res)\n",
    "            cv2.moveWindow(\"DEBUG1\", 450, 50)\n",
    "            cv2.moveWindow(\"DEBUG2\", 450, 150)\n",
    "            cv2.moveWindow(\"DEBUG3\", 450, 250)\n",
    "            cv2.moveWindow(\"DEBUG5\", 450, 450)\n",
    "            cv2.moveWindow(\"DEBUG6\", 450, 550)\n",
    "            cnts = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            for c in cnts:\n",
    "                M = cv2.moments(c)\n",
    "                c = c.astype(\"float\")\n",
    "                c = c.astype(\"int\")\n",
    "                cv2.drawContours(test2, [c], -1, (0, 255, 0), 1)\n",
    "            cv2.imshow(\"DEBUG4\", test2)\n",
    "            cv2.moveWindow(\"DEBUG4\", 450, 350)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
    "    if output_path != '': cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        # Show the image\n",
    "        height, width, channels = image.shape\n",
    "        resize = 0\n",
    "        if height > width:\n",
    "            resize = ResizeWithAspectRatio(image, height=900)\n",
    "        else:\n",
    "            resize = ResizeWithAspectRatio(image, width=900)\n",
    "        cv2.imshow(\"predicted image\", resize)\n",
    "        height, width, channels = resize.shape\n",
    "        cv2.moveWindow(\"predicted image\", int(2560/2) - int(width/2), int(1080/2) - int(height/2))\n",
    "        # Load and hold the image\n",
    "        \n",
    "    cv2.waitKey(0)\n",
    "    # To close the window after the required kill value was provided\n",
    "    cv2.destroyAllWindows()\n",
    "    return image\n",
    "\n",
    "def detect_video(YoloV3, video_path, output_path, input_size=416, show=False, CLASSES=YOLO_LABELS, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
    "    times = []\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # by default VideoCapture returns float instead of int\n",
    "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, codec, fps, (width, height)) # output_path must be .mp4\n",
    "\n",
    "    while True:\n",
    "        _, img = vid.read()\n",
    "\n",
    "        try:\n",
    "            original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            break\n",
    "        image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "        image_data = tf.expand_dims(image_data, 0)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        pred_bbox = YoloV3.predict(image_data)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
    "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "        \n",
    "        times.append(t2-t1)\n",
    "        times = times[-20:]\n",
    "        \n",
    "        ms = sum(times)/len(times)*1000\n",
    "        fps = 1000 / ms\n",
    "        \n",
    "        print(\"Time: {:.2f}ms, {:.1f} FPS\".format(ms, fps))\n",
    "\n",
    "        image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
    "        image = cv2.putText(image, \"Time: {:.1f}FPS\".format(fps), (0, 30),\n",
    "                          cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if output_path != '': out.write(image)\n",
    "        if show:\n",
    "            cv2.imshow('output', image)\n",
    "            if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# detect from webcam\n",
    "def detect_realtime(YoloV3, output_path, input_size=416, show=False, CLASSES=YOLO_LABELS, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
    "    times = []\n",
    "    vid = cv2.VideoCapture(0)\n",
    "\n",
    "    # by default VideoCapture returns float instead of int\n",
    "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, codec, fps, (width, height)) # output_path must be .mp4\n",
    "\n",
    "    while True:\n",
    "        _, frame = vid.read()\n",
    "\n",
    "        try:\n",
    "            original_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            break\n",
    "        image_frame = image_preprocess(np.copy(original_frame), [input_size, input_size])\n",
    "        image_frame = tf.expand_dims(image_frame, 0)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        pred_bbox = YoloV3.predict(image_frame)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        bboxes = postprocess_boxes(pred_bbox, original_frame, input_size, score_threshold)\n",
    "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "        \n",
    "        times.append(t2-t1)\n",
    "        times = times[-20:]\n",
    "        \n",
    "        ms = sum(times)/len(times)*1000\n",
    "        fps = 1000 / ms\n",
    "        \n",
    "        print(\"Time: {:.2f}ms, {:.1f} FPS\".format(ms, fps))\n",
    "\n",
    "        frame = draw_bbox(original_frame, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
    "        image = cv2.putText(frame, \"Time: {:.1f}FPS\".format(fps), (0, 30),\n",
    "                          cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if output_path != '': out.write(frame)\n",
    "        if show:\n",
    "            cv2.imshow('output', frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\t\t\t\n",
    "def train():\n",
    "    gpu = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    print(\"Detected GPUs: \" + str(gpu));\n",
    "    \n",
    "    if len(gpu) > 0:\n",
    "        tf.config.experimental.set_memory_growth(gpu[0], True) #Allow GPU memory to grow\n",
    "    \n",
    "    train_set = Dataset(\"train\", INPUT_SIZE_TRAIN)\n",
    "    test_set = Dataset(\"test\", INPUT_SIZE_TEST)\n",
    "    \n",
    "    steps_per_epoch = len(train_set)\n",
    "    global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "    warmup_steps = WARMUP_EPOCHS * steps_per_epoch\n",
    "    total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "    writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "    Darknet_weights = YOLO_WEIGHTS\n",
    "    Darknet = CreateYolo(input_size = YOLO_INPUT_SIZE)\n",
    "    load_yolo_weights(Darknet, Darknet_weights)\n",
    "    yolo = CreateYolo(input_size = YOLO_INPUT_SIZE, training=True, classes=LABEL_PATH)\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layers_weights = l.get_weights()\n",
    "        if layers_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layers_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    def train_step(image_data, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_result = yolo(image_data, training=True)\n",
    "            giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "            # optimizing process\n",
    "            grid = 3\n",
    "            for i in range(grid):\n",
    "                conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                loss_items = compute_loss(pred, conv, *target[i], i, classes=LABEL_PATH)\n",
    "                giou_loss += loss_items[0]\n",
    "                conf_loss += loss_items[1]\n",
    "                prob_loss += loss_items[2]\n",
    "\n",
    "            total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "            gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "            # update learning rate\n",
    "            # about warmup: https://arxiv.org/pdf/1812.01187.pdf&usg=ALkJrhglKOPDjNt6SHGbphTHyMcT0cuMJg\n",
    "            global_steps.assign_add(1)\n",
    "            if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "                lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "            else:\n",
    "                lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                    (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "            optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "            # writing summary data\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "                tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "            writer.flush()\n",
    "            \n",
    "        return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "    \n",
    "    validate_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "    def validate_step(image_data, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred_result = yolo(image_data, training=False)\n",
    "            giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "            # optimizing process\n",
    "            grid = 3\n",
    "            for i in range(grid):\n",
    "                conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                loss_items = compute_loss(pred, conv, *target[i], i, classes=LABEL_PATH)\n",
    "                giou_loss += loss_items[0]\n",
    "                conf_loss += loss_items[1]\n",
    "                prob_loss += loss_items[2]\n",
    "\n",
    "            total_loss = giou_loss + conf_loss + prob_loss\n",
    "            \n",
    "        return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n",
    "    \n",
    "    best_val_loss = 1000 # should be large at start\n",
    "    for epoch in range(TRAIN_EPOCHS):\n",
    "        for image_data, target in train_set:\n",
    "            results = train_step(image_data, target)\n",
    "            cur_step = results[0]%steps_per_epoch\n",
    "            print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "                  .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    "        if len(test_set) == 0:\n",
    "            print(\"configure TEST options to validate model\")\n",
    "            yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "            continue\n",
    "        \n",
    "        count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "        for image_data, target in test_set:\n",
    "            results = validate_step(image_data, target)\n",
    "            count += 1\n",
    "            giou_val += results[0]\n",
    "            conf_val += results[1]\n",
    "            prob_val += results[2]\n",
    "            total_val += results[3]\n",
    "        # writing validate summary data\n",
    "        with validate_writer.as_default():\n",
    "            tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "            tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "        validate_writer.flush()\n",
    "            \n",
    "        print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "              format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "\n",
    "        if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "            save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "            yolo.save_weights(save_directory)\n",
    "        if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/count:\n",
    "            save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "            yolo.save_weights(save_directory)\n",
    "            best_val_loss = total_val/count\n",
    "        if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "            save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "            yolo.save_weights(save_directory)\n",
    "\n",
    "    # measure mAP of trained custom model\n",
    "    #model = Create_Yolov3(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "    #model.load_weights(save_directory) # use keras weights\t\t\t\n",
    "\t\n",
    "\n",
    "\n",
    "def detect():\n",
    "    yolo = CreateYolo(input_size=YOLO_INPUT_SIZE, classes=LABEL_PATH)\n",
    "    yolo.load_weights(\"./checkpoints2/yolov3_resistors\") # use keras weights\n",
    "    for x in range(13):\n",
    "        image_path = \"./myimg2/\" + str(x + 1) + \".jpg\"\n",
    "        detect_image(yolo, image_path, \"./myimg2/\" + str(x + 1) + \"_detect.jpg\", score_threshold=0.50, input_size=YOLO_INPUT_SIZE, show=True, CLASSES=LABEL_PATH, rectangle_colors=(255,0,0))\n",
    "    \n",
    "def validContour(cnt):\n",
    "    #looking for a large enough area and correct aspect ratio\n",
    "    if(cv2.contourArea(cnt) < MIN_AREA):\n",
    "        return False\n",
    "    else:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        aspectRatio = float(w)/h\n",
    "        if (aspectRatio > 0.4):\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def printResult(sortedBands, liveimg, resPos):\n",
    "    x,y,w,h = resPos\n",
    "    strVal = \"\"\n",
    "    if (len(sortedBands) in [3,4,5]):\n",
    "        for band in sortedBands[:-1]:\n",
    "            strVal += str(band[3])\n",
    "        intVal = int(strVal)\n",
    "        intVal *= 10**sortedBands[-1][3]\n",
    "        cv2.rectangle(liveimg,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(liveimg,str(intVal) + \" OHMS\",(x+w+10,y), FONT, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        return\n",
    "    #draw a red rectangle indicating an error reading the bands\n",
    "    cv2.rectangle(liveimg,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    \n",
    "def findResistors(liveimg, rectCascade):\n",
    "    gliveimg = cv2.cvtColor(liveimg, cv2.COLOR_BGR2GRAY)\n",
    "    resClose = []\n",
    "\n",
    "    #detect resistors in main frame\n",
    "    ressFind = rectCascade.detectMultiScale(gliveimg,1.1,25)\n",
    "    for (x,y,w,h) in ressFind: #SWITCH TO H,W FOR <CV3\n",
    "        \n",
    "        roi_gray = gliveimg[y:y+h, x:x+w]\n",
    "        roi_color = liveimg[y:y+h, x:x+w]\n",
    "\n",
    "        #apply another detection to filter false positives\n",
    "        secondPass = rectCascade.detectMultiScale(roi_gray,1.01,5)\n",
    "\n",
    "        if (len(secondPass) != 0):\n",
    "            resClose.append((np.copy(roi_color),(x,y,w,h)))\n",
    "    return resClose\n",
    "\n",
    "def printResult(sortedBands, liveimg, resPos):\n",
    "    x,y,w,h = resPos\n",
    "    strVal = \"\"\n",
    "    if (len(sortedBands) in [3,4,5]):\n",
    "        for band in sortedBands[:-1]:\n",
    "            strVal += str(band[3])\n",
    "        intVal = int(strVal)\n",
    "        intVal *= 10**sortedBands[-1][3]\n",
    "        cv2.rectangle(liveimg,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(liveimg,str(intVal) + \" OHMS\",(x+w+10,y), FONT, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        return\n",
    "    #draw a red rectangle indicating an error reading the bands\n",
    "    cv2.rectangle(liveimg,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    \n",
    "def findBands(resistorInfo, DEBUG):\n",
    "    if (DEBUG):\n",
    "        uh = cv2.getTrackbarPos(\"uh\",\"frame\")\n",
    "        us = cv2.getTrackbarPos(\"us\",\"frame\")\n",
    "        uv = cv2.getTrackbarPos(\"uv\",\"frame\")\n",
    "        lh = cv2.getTrackbarPos(\"lh\",\"frame\")\n",
    "        ls = cv2.getTrackbarPos(\"ls\",\"frame\")\n",
    "        lv = cv2.getTrackbarPos(\"lv\",\"frame\")\n",
    "    #enlarge image\n",
    "    resImg = cv2.resize(resistorInfo[0], (400, 200))\n",
    "    #apply bilateral filter and convert to hsv                                          \n",
    "    pre_bil = cv2.bilateralFilter(resImg,5,80,80)\n",
    "    hsv = cv2.cvtColor(pre_bil, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #edge threshold filters out background and resistor body\n",
    "    thresh = cv2.adaptiveThreshold(cv2.cvtColor(pre_bil, cv2.COLOR_BGR2GRAY),255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,59,5)\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    bandsPos = []\n",
    "\n",
    "    #if in debug mode, check only one colour\n",
    "    checkColours = COLOUR_BOUNDS\n",
    "\n",
    "    for clr in checkColours:\n",
    "        mask = cv2.inRange(hsv, clr[0], clr[1])\n",
    "        if (clr[2] == \"RED\"): #combining the 2 RED ranges in hsv\n",
    "            redMask2 = cv2.inRange(hsv, RED_TOP_LOWER, RED_TOP_UPPER)\n",
    "            mask = cv2.bitwise_or(redMask2,mask,mask)\n",
    "             \n",
    "        mask = cv2.bitwise_and(mask,thresh,mask= mask)\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #filter invalid contours, store valid ones\n",
    "        for k in range(len(contours)-1,-1,-1):\n",
    "            #if (validContour(contours[k])):\n",
    "            leftmostPoint = tuple(contours[k][contours[k][:,:,0].argmin()][0])\n",
    "            bandsPos += [leftmostPoint + tuple(clr[2:])]\n",
    "            cv2.circle(pre_bil, leftmostPoint, 5, (255,0,255),-1)\n",
    "            #else:\n",
    "            #    contours.pop(k)\n",
    "        \n",
    "        cv2.drawContours(pre_bil, contours, -1, clr[-1], 3)                                \n",
    "\n",
    "    cv2.imshow('Contour Display', pre_bil)#shows the most recent resistor checked.\n",
    "    #sort by 1st element of each tuple and return\n",
    "    print(\"BANDS: \")\n",
    "    print(bandsPos)\n",
    "    return sorted(bandsPos, key=lambda tup: tup[0])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(os.getcwd())\n",
    "    #XMLtoYOLO()\n",
    "    #train()\n",
    "    detect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
